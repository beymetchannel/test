import time
import json
import re 
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, WebDriverException

# ==========================================================
# ğŸ”´ å®šæ•°å®šç¾©
# ==========================================================
IFRAME_URL = "https://beyblade.takaratomy.co.jp/beyblade-x/shop_event/manage_jpnew/open_list_all.html"
OUTPUT_JSON_FILENAME = "events.json"
TABLE_SELECTOR = "table.event_list"
WAIT_TIMEOUT = 30
# ==========================================================

# éƒ½é“åºœçœŒåã®ãƒªã‚¹ãƒˆ
PREFECTURES = [
    "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ", 
    "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ", 
    "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ", 
    "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ", 
    "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ", 
    "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ", 
    "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
]


def fetch_schedule_data(url):
    """
    Seleniumã‚’ä½¿ç”¨ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
    (Col1ã®æŠ½å‡ºæ¡ä»¶ä¿®æ­£: å½“æ—¥å—ä»˜ã‚’entryã¸)
    """
    print(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")

    options = webdriver.ChromeOptions()
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--headless')

    try:
        driver_path = ChromeDriverManager().install()
        service = Service(driver_path)
        driver = webdriver.Chrome(service=service, options=options)
    except Exception as e:
        print(f"WebDriverã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

    try:
        driver.get(url)
        wait = WebDriverWait(driver, WAIT_TIMEOUT)

        print(f"ãƒ†ãƒ¼ãƒ–ãƒ«è¦ç´  ('{TABLE_SELECTOR}') ã®ãƒ­ãƒ¼ãƒ‰ã‚’å¾…æ©Ÿä¸­...")
        table_element = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, TABLE_SELECTOR))
        )

        time.sleep(2)

        events_data = []
        rows = table_element.find_elements(By.TAG_NAME, 'tr')

        if len(rows) <= 1:
            print("ğŸš¨ è­¦å‘Š: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã—ã‹è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return []

        print(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã« {len(rows)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™ã€‚")

        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ (rows[0]) ã¯ã‚¹ã‚­ãƒƒãƒ—
        for i, row in enumerate(rows[1:]):
            row_index = i + 1
            cols = row.find_elements(By.TAG_NAME, 'td')

            if len(cols) != 2:
                continue

            try:
                col1_text = cols[0].text.strip()
                col2_text = cols[1].text.strip()

                # -------------------------------------------------------
                # 1. Col 1 Parsing (Typeåˆ†è§£ãƒ­ã‚¸ãƒƒã‚¯)
                # -------------------------------------------------------
                
                # Date & Time
                date_match = re.search(r'(\d{4}å¹´\s*\d{1,2}æœˆ\s*\d{1,2}æ—¥)', col1_text)
                date_info = date_match.group(1).strip() if date_match else "æ—¥ä»˜ä¸æ˜"

                time_match = re.search(r'(\d{1,2}ï¼š\d{2})', col1_text)
                time_info = time_match.group(1).strip() if time_match else "æ™‚é–“ä¸æ˜"

                # Raw Type Extraction
                type_start_index = col1_text.find(time_info) + len(time_info)
                type_end_index = col1_text.find("è©³ç´°ã¯ã“ã¡ã‚‰")
                
                raw_type_lines = []
                if type_start_index != -1 and type_end_index != -1 and type_end_index > type_start_index:
                    raw_text = col1_text[type_start_index:type_end_index].strip()
                    # ä¸è¦ãªæ–‡å­—ã‚’å‰Šé™¤
                    raw_text = raw_text.replace('Share', '').replace('X-TREME', '').strip()
                    raw_type_lines = raw_text.split('\n')
                
                # Typeã®ä¸­èº«ã‚’åˆ†åˆ¥
                final_type_lines = []
                col1_fee_parts = []
                col1_entry_parts = [] 

                for line in raw_type_lines:
                    line = line.strip()
                    if not line: continue

                    # æ¡ä»¶åˆ†å²ã®ä¿®æ­£ç®‡æ‰€
                    if "å‚åŠ è²»ï¼š" in line:
                        col1_fee_parts.append(line)
                    elif "å½“æ—¥å—ä»˜ï¼š" in line:   # ğŸ‘ˆ ã“ã“ã‚’ä¿®æ­£ (æ—§: å‚åŠ è³‡æ ¼)
                        col1_entry_parts.append(line)
                    else:
                        final_type_lines.append(line)
                
                event_type = "\n".join(final_type_lines).strip()
                if not event_type: event_type = "ç¨®åˆ¥ä¸æ˜"


                # -------------------------------------------------------
                # 2. Col 2 Parsing (Consumed Indices & çµ±åˆ)
                # -------------------------------------------------------
                
                lines2 = [line.strip() for line in col2_text.split('\n') if line.strip()]
                num_lines = len(lines2)
                consumed_indices = set()

                # çµæœæ ¼ç´ç”¨ãƒªã‚¹ãƒˆï¼ˆCol 1ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸå€¤ã¨ã—ã¦å…¥ã‚Œã‚‹ï¼‰
                fee_parts = col1_fee_parts[:]
                entry_parts = col1_entry_parts[:] 
                
                event_name = "åå‰ä¸æ˜"
                location = "-"
                capacity = "-"
                eligibility = "-"
                address_info = "-"

                # (1) Name (1è¡Œç›®)
                if num_lines > 0:
                    event_name = lines2[0]
                    consumed_indices.add(0)

                # (2) Location (2è¡Œç›®)
                if num_lines > 1:
                    if "å®šå“¡æ•° " not in lines2[1]:
                        location = lines2[1]
                        consumed_indices.add(1)
                    else:
                        location = "-"
                        # "å®šå“¡æ•°"ã‚’å«ã‚€å ´åˆã¯ã“ã“ã§ã¯å‡¦ç†ã›ãšã€ãƒ«ãƒ¼ãƒ—ã§æ‹¾ã†

                # (3) Loop for others
                for idx, line in enumerate(lines2):
                    if idx in consumed_indices:
                        continue

                    # --- Fee (å‚åŠ è²») ---
                    if "å‚åŠ è²»ï¼š" in line:
                        fee_parts.append(line)
                        consumed_indices.add(idx)
                    
                    # --- Capacity (å®šå“¡æ•°) ---
                    elif "å®šå“¡æ•° " in line:
                        capacity = line
                        consumed_indices.add(idx)

                    # --- Eligibility (å‚åŠ è³‡æ ¼) ---
                    elif "å‚åŠ è³‡æ ¼ï¼š" in line:
                        eligibility = line
                        consumed_indices.add(idx)

                    # --- Address (ä½æ‰€) ---
                    elif any(line.startswith(pref) for pref in PREFECTURES):
                        address_info = line
                        consumed_indices.add(idx)
                    
                    # --- Entry Logic A: "å½“æ—¥å—ä»˜ï¼š" ---
                    elif "å½“æ—¥å—ä»˜ï¼š" in line:
                        entry_parts.append(line)
                        consumed_indices.add(idx)
                    
                    # --- Entry Logic B: "å‚åŠ æ–¹æ³•" ---
                    elif "å‚åŠ æ–¹æ³•" in line:
                        consumed_indices.add(idx) # ãƒ©ãƒ™ãƒ«è¡Œã‚’ä½¿ç”¨æ¸ˆã¿ã«
                        next_idx = idx + 1
                        if next_idx < num_lines:
                            entry_parts.append(lines2[next_idx])
                            consumed_indices.add(next_idx) # æ¬¡ã®è¡Œã‚‚ä½¿ç”¨æ¸ˆã¿ã«

                # ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ãƒ»çµåˆ
                fee_info = "\n".join(fee_parts) if fee_parts else "-"
                entry_info = "\n".join(entry_parts) if entry_parts else "-"

                # Details (æ®‹ã‚Š)
                details_list = []
                for idx, line in enumerate(lines2):
                    if idx not in consumed_indices:
                        details_list.append(line)
                
                location_details = "\n".join(details_list).strip()
                if not location_details:
                    location_details = "è©³ç´°æƒ…å ±ãªã—"

                events_data.append({
                    "date": date_info,
                    "time": time_info,
                    "name": event_name,
                    "location": location,
                    "type": event_type,         # Col 1ã®æ®‹ã‚Š
                    "fee": fee_info,            # Col 1 + Col 2
                    "capacity": capacity,
                    "eligibility": eligibility, 
                    "address": address_info,
                    "entry": entry_info,        # Col 1(å½“æ—¥å—ä»˜) + Col 2(å½“æ—¥å—ä»˜/å‚åŠ æ–¹æ³•)
                    "details": location_details
                })

            except Exception as row_e:
                print(f"âŒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {row_index}è¡Œç›®ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {row_e}")
                continue

        print(f"âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ {len(events_data)} ä»¶ã®æŠ½å‡ºã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return events_data

    except TimeoutException:
        print(f"\nğŸ›‘ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        return None
    except WebDriverException as e:
        print(f"\nâŒ WebDriveré€šä¿¡ã‚¨ãƒ©ãƒ¼: {e.msg}")
        return None
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        driver.quit()


def save_to_json(data, filename):
    if not data:
        return
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"âœ… ä¿å­˜å®Œäº†: {filename}")
    except IOError as e:
        print(f"æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    extracted_data = fetch_schedule_data(IFRAME_URL)
    if extracted_data is not None:
        save_to_json(extracted_data, OUTPUT_JSON_FILENAME)
